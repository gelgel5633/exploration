{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "29c6cf56",
      "metadata": {
        "id": "29c6cf56"
      },
      "source": [
        "# 뉴스 클래스 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "08b14ab0",
      "metadata": {
        "id": "08b14ab0"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score #정확도 계산\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa374c50",
      "metadata": {
        "id": "fa374c50"
      },
      "source": [
        "# 1. 모든 단어를 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a1e07b52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1e07b52",
        "outputId": "1f6da464-6270-4aeb-b96e-7814de476cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#num_words는 상위 몇 번째 단어까지 사용할 것인지 \n",
        "#num_words인자를 명시하지 않았을 경우 모든 데이터 사용\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(test_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6ba5fb62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ba5fb62",
        "outputId": "13c38280-88b1-4f05-968d-473d225f5387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플의 수: 8982\n",
            "테스트 샘플의 수: 2246\n",
            "클래스의 수 : 46\n"
          ]
        }
      ],
      "source": [
        "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
        "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
        "num_classes = max(y_train) + 1\n",
        "print('클래스의 수 : {}'.format(num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8b7da4f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b7da4f0",
        "outputId": "29b9e61b-6794-4416-9b71-d2af98e75a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "565248/550378 [==============================] - 0s 0us/step\n",
            "8982\n",
            "2246\n"
          ]
        }
      ],
      "source": [
        "#데이터 복원부분\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "# +3을 한 숫자가 원래 숫자가됨. pad sos unk때문\n",
        "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
        "\n",
        "# index_to_word에 0은 <pad>, 1은 <sos>, 2는 <unk>를 넣기\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token\n",
        "\n",
        "#훈련용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "    \n",
        "x_train = decoded\n",
        "print(len(x_train))\n",
        "\n",
        "#테스트용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fc77eb8a",
      "metadata": {
        "id": "fc77eb8a"
      },
      "outputs": [],
      "source": [
        "#벡터화부분\n",
        "\n",
        "#dtm 생성, dtm이 자체규칙에 따라 불필요하다고 판단하는 토큰을 제거함\n",
        "dtmvector = CountVectorizer()\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "# train에 대한 document - term maxtrix, tfidf 생성\n",
        "x_train_dtm = dtmvector.fit_transform(x_train) #train 데이터를 DTM으로 변환\n",
        "tfidfv = tfidf_transformer.fit_transform(x_train_dtm) #DTM을 TF-IDF 행렬로 변환\n",
        "\n",
        "# test에 대한 document - term maxtrix, tfidf 생성\n",
        "x_test_dtm = dtmvector.transform(x_test) \n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d29e58ee",
      "metadata": {
        "id": "d29e58ee"
      },
      "outputs": [],
      "source": [
        "#모델정의부분\n",
        "\n",
        "nb = MultinomialNB() #나이브베이즈 분류기\n",
        "cb = ComplementNB() #컴플리먼트 나이브 베이즈 분류기 - 나이브베이즈 분류기 개선\n",
        "lr = LogisticRegression(C=10000, penalty='l2') #로지스틱회귀 - 이름은 회귀지만 분류모델\n",
        "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False) # 서포트벡터머신(svm) 사용\n",
        "tree = DecisionTreeClassifier(max_depth=10, random_state=0) #의사결정나무\n",
        "forest = RandomForestClassifier(n_estimators=5, random_state=0) #랜덤포레스트\n",
        "grbt = GradientBoostingClassifier(random_state=0) # 그라디언트부스팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "40c98a25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40c98a25",
        "outputId": "be7e48d5-5406-43c1-a968-45b114118886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나이브베이즈 정확도: 0.5997328584149599\n",
            "컴플리먼트 나이브 베이즈 정확도: 0.7649154051647373\n",
            "로지스틱 회귀 정확도: 0.813446126447017\n",
            "서포트 벡터 머신 정확도: 0.7827248441674087\n",
            "decision tree 정확도: 0.6211041852181657\n",
            "random forest 정확도: 0.6544968833481746\n",
            "gradient boosting 정확도: 0.7702582368655387\n"
          ]
        }
      ],
      "source": [
        "nb.fit(tfidfv, y_train)\n",
        "predicted_n = nb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"나이브베이즈 정확도:\", accuracy_score(y_test, predicted_n)) #예측값과 실제값 비교\n",
        "\n",
        "cb.fit(tfidfv, y_train)\n",
        "predicted_c = cb.predict(tfidfv_test)\n",
        "print(\"컴플리먼트 나이브 베이즈 정확도:\", accuracy_score(y_test, predicted_c))\n",
        "\n",
        "lr.fit(tfidfv, y_train)\n",
        "predicted_l = lr.predict(tfidfv_test)\n",
        "print(\"로지스틱 회귀 정확도:\", accuracy_score(y_test, predicted_l))\n",
        "\n",
        "lsvc.fit(tfidfv, y_train)\n",
        "predicted_ls = lsvc.predict(tfidfv_test)\n",
        "print(\"서포트 벡터 머신 정확도:\", accuracy_score(y_test, predicted_ls))\n",
        "\n",
        "tree.fit(tfidfv, y_train)\n",
        "predicted_t = tree.predict(tfidfv_test)\n",
        "print(\"decision tree 정확도:\", accuracy_score(y_test, predicted_t))\n",
        "\n",
        "forest.fit(tfidfv, y_train)\n",
        "predicted_f = forest.predict(tfidfv_test)\n",
        "print(\"random forest 정확도:\", accuracy_score(y_test, predicted_f))\n",
        "\n",
        "grbt.fit(tfidfv, y_train)\n",
        "predicted_gb = grbt.predict(tfidfv_test)\n",
        "print(\"gradient boosting 정확도:\", accuracy_score(y_test, predicted_gb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "88830cab",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88830cab",
        "outputId": "c376d75d-3521-4e11-b61d-572ffbc68c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8187889581478184\n"
          ]
        }
      ],
      "source": [
        "# 소프트 보팅 사용\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "        ('cb', ComplementNB()),\n",
        "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "], voting='soft', n_jobs=-1)\n",
        "voting_classifier.fit(tfidfv, y_train)\n",
        "\n",
        "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66ea1fce",
      "metadata": {
        "id": "66ea1fce"
      },
      "source": [
        "1차 점수 - 모든 단어\n",
        "* 나이브베이즈 정확도: 0.5997328584149599\n",
        "* 컴플리먼트 나이브 베이즈 정확도: 0.7649154051647373\n",
        "* 로지스틱 회귀 정확도: 0.813446126447017\n",
        "* 서포트 벡터 머신 정확도: 0.7827248441674087\n",
        "* decision tree 정확도: 0.6211041852181657\n",
        "* random forest 정확도: 0.6544968833481746\n",
        "* gradient boosting 정확도: 0.7702582368655387\n",
        "* 보팅 : 0.8187889581478184"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def83616",
      "metadata": {
        "id": "def83616"
      },
      "source": [
        "# 2. 빈도수 5000개 단어를 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "35d295e9",
      "metadata": {
        "id": "35d295e9"
      },
      "outputs": [],
      "source": [
        "#num_words는 상위 몇 번째 단어까지 사용할 것인지 \n",
        "#num_words인자를 명시하지 않았을 경우 모든 데이터 사용\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e89cab5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e89cab5b",
        "outputId": "e6356b4a-f3f1-4f69-c899-008c26adbffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n",
            "2246\n"
          ]
        }
      ],
      "source": [
        "#데이터 복원부분\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "# +3을 한 숫자가 원래 숫자가됨. pad sos unk때문\n",
        "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
        "\n",
        "# index_to_word에 0은 <pad>, 1은 <sos>, 2는 <unk>를 넣기\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token\n",
        "\n",
        "#훈련용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "    \n",
        "x_train = decoded\n",
        "print(len(x_train))\n",
        "\n",
        "#테스트용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "892ea89a",
      "metadata": {
        "id": "892ea89a"
      },
      "outputs": [],
      "source": [
        "#벡터화부분\n",
        "\n",
        "#dtm 생성, dtm이 자체규칙에 따라 불필요하다고 판단하는 토큰을 제거함\n",
        "dtmvector = CountVectorizer()\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "# train에 대한 document - term maxtrix, tfidf 생성\n",
        "x_train_dtm = dtmvector.fit_transform(x_train) #train 데이터를 DTM으로 변환\n",
        "tfidfv = tfidf_transformer.fit_transform(x_train_dtm) #DTM을 TF-IDF 행렬로 변환\n",
        "\n",
        "# test에 대한 document - term maxtrix, tfidf 생성\n",
        "x_test_dtm = dtmvector.transform(x_test) \n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cffe1cef",
      "metadata": {
        "id": "cffe1cef"
      },
      "outputs": [],
      "source": [
        "#모델정의부분\n",
        "\n",
        "nb = MultinomialNB() #나이브베이즈 분류기\n",
        "cb = ComplementNB() #컴플리먼트 나이브 베이즈 분류기 - 나이브베이즈 분류기 개선\n",
        "lr = LogisticRegression(C=10000, penalty='l2') #로지스틱회귀 - 이름은 회귀지만 분류모델\n",
        "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False) # 서포트벡터머신(svm) 사용\n",
        "tree = DecisionTreeClassifier(max_depth=10, random_state=0) #의사결정나무\n",
        "forest = RandomForestClassifier(n_estimators=5, random_state=0) #랜덤포레스트\n",
        "grbt = GradientBoostingClassifier(random_state=0) # 그라디언트부스팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ddbd151a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddbd151a",
        "outputId": "4a6cffb7-d77e-48c1-8946-abc87bb21dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나이브베이즈 정확도: 0.6731967943009796\n",
            "컴플리먼트 나이브 베이즈 정확도: 0.7707034728406055\n",
            "로지스틱 회귀 정확도: 0.8058771148708815\n",
            "서포트 벡터 머신 정확도: 0.7658058771148709\n",
            "decision tree 정확도: 0.6179875333926982\n",
            "random forest 정확도: 0.701246660730187\n",
            "gradient boosting 정확도: 0.767586821015138\n"
          ]
        }
      ],
      "source": [
        "nb.fit(tfidfv, y_train)\n",
        "predicted_n = nb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"나이브베이즈 정확도:\", accuracy_score(y_test, predicted_n)) #예측값과 실제값 비교\n",
        "\n",
        "cb.fit(tfidfv, y_train)\n",
        "predicted_c = cb.predict(tfidfv_test)\n",
        "print(\"컴플리먼트 나이브 베이즈 정확도:\", accuracy_score(y_test, predicted_c))\n",
        "\n",
        "lr.fit(tfidfv, y_train)\n",
        "predicted_l = lr.predict(tfidfv_test)\n",
        "print(\"로지스틱 회귀 정확도:\", accuracy_score(y_test, predicted_l))\n",
        "\n",
        "lsvc.fit(tfidfv, y_train)\n",
        "predicted_ls = lsvc.predict(tfidfv_test)\n",
        "print(\"서포트 벡터 머신 정확도:\", accuracy_score(y_test, predicted_ls))\n",
        "\n",
        "tree.fit(tfidfv, y_train)\n",
        "predicted_t = tree.predict(tfidfv_test)\n",
        "print(\"decision tree 정확도:\", accuracy_score(y_test, predicted_t))\n",
        "\n",
        "forest.fit(tfidfv, y_train)\n",
        "predicted_f = forest.predict(tfidfv_test)\n",
        "print(\"random forest 정확도:\", accuracy_score(y_test, predicted_f))\n",
        "\n",
        "grbt.fit(tfidfv, y_train)\n",
        "predicted_gb = grbt.predict(tfidfv_test)\n",
        "print(\"gradient boosting 정확도:\", accuracy_score(y_test, predicted_gb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d88586d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d88586d5",
        "outputId": "cb17100a-60ff-4600-97ef-5f175ab8626d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8161175422974176\n"
          ]
        }
      ],
      "source": [
        "# 소프트 보팅 사용\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "        ('cb', ComplementNB()),\n",
        "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "], voting='soft', n_jobs=-1)\n",
        "voting_classifier.fit(tfidfv, y_train)\n",
        "\n",
        "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ef3280",
      "metadata": {
        "id": "73ef3280"
      },
      "source": [
        "2차 점수 - 단어 5000개\n",
        "* 나이브베이즈 정확도: 0.6731967943009796\n",
        "* 컴플리먼트 나이브 베이즈 정확도: 0.7707034728406055\n",
        "* 로지스틱 회귀 정확도: 0.8058771148708815\n",
        "* 서포트 벡터 머신 정확도: 0.7658058771148709\n",
        "* decision tree 정확도: 0.6179875333926982\n",
        "* random forest 정확도: 0.701246660730187\n",
        "* gradient boosting 정확도: 0.767586821015138\n",
        "* 보팅 : 0.8161175422974176"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c59359e2",
      "metadata": {
        "id": "c59359e2"
      },
      "source": [
        "# 3. 빈도수 15000개 단어를 사용하기(직접 넣은수치 - 보팅으로 인한 정확도가 소폭 하락했기 때문)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "982990ea",
      "metadata": {
        "id": "982990ea"
      },
      "outputs": [],
      "source": [
        "#num_words는 상위 몇 번째 단어까지 사용할 것인지 \n",
        "#num_words인자를 명시하지 않았을 경우 모든 데이터 사용\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=15000, test_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "efea83ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efea83ed",
        "outputId": "650e4003-656e-4ee3-ec5f-f1c34a9bc8e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n",
            "2246\n"
          ]
        }
      ],
      "source": [
        "#데이터 복원부분\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "# +3을 한 숫자가 원래 숫자가됨. pad sos unk때문\n",
        "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
        "\n",
        "# index_to_word에 0은 <pad>, 1은 <sos>, 2는 <unk>를 넣기\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token\n",
        "\n",
        "#훈련용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "    \n",
        "x_train = decoded\n",
        "print(len(x_train))\n",
        "\n",
        "#테스트용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "53a14552",
      "metadata": {
        "id": "53a14552"
      },
      "outputs": [],
      "source": [
        "#벡터화부분\n",
        "\n",
        "#dtm 생성, dtm이 자체규칙에 따라 불필요하다고 판단하는 토큰을 제거함\n",
        "dtmvector = CountVectorizer()\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "# train에 대한 document - term maxtrix, tfidf 생성\n",
        "x_train_dtm = dtmvector.fit_transform(x_train) #train 데이터를 DTM으로 변환\n",
        "tfidfv = tfidf_transformer.fit_transform(x_train_dtm) #DTM을 TF-IDF 행렬로 변환\n",
        "\n",
        "# test에 대한 document - term maxtrix, tfidf 생성\n",
        "x_test_dtm = dtmvector.transform(x_test) \n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c1194ce7",
      "metadata": {
        "id": "c1194ce7"
      },
      "outputs": [],
      "source": [
        "#모델정의부분\n",
        "\n",
        "nb = MultinomialNB() #나이브베이즈 분류기\n",
        "cb = ComplementNB() #컴플리먼트 나이브 베이즈 분류기 - 나이브베이즈 분류기 개선\n",
        "lr = LogisticRegression(C=10000, penalty='l2') #로지스틱회귀 - 이름은 회귀지만 분류모델\n",
        "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False) # 서포트벡터머신(svm) 사용\n",
        "tree = DecisionTreeClassifier(max_depth=10, random_state=0) #의사결정나무\n",
        "forest = RandomForestClassifier(n_estimators=5, random_state=0) #랜덤포레스트\n",
        "grbt = GradientBoostingClassifier(random_state=0) # 그라디언트부스팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bbd86ad8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbd86ad8",
        "outputId": "582b2c39-880f-4683-ab4f-9fe81a5eb96a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나이브베이즈 정확도: 0.6331255565449688\n",
            "컴플리먼트 나이브 베이즈 정확도: 0.7720391807658059\n",
            "로지스틱 회귀 정확도: 0.8125556544968834\n",
            "서포트 벡터 머신 정확도: 0.7742653606411398\n",
            "decision tree 정확도: 0.6193232413178985\n",
            "random forest 정확도: 0.6714158504007124\n",
            "gradient boosting 정확도: 0.7707034728406055\n"
          ]
        }
      ],
      "source": [
        "nb.fit(tfidfv, y_train)\n",
        "predicted_n = nb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"나이브베이즈 정확도:\", accuracy_score(y_test, predicted_n)) #예측값과 실제값 비교\n",
        "\n",
        "cb.fit(tfidfv, y_train)\n",
        "predicted_c = cb.predict(tfidfv_test)\n",
        "print(\"컴플리먼트 나이브 베이즈 정확도:\", accuracy_score(y_test, predicted_c))\n",
        "\n",
        "lr.fit(tfidfv, y_train)\n",
        "predicted_l = lr.predict(tfidfv_test)\n",
        "print(\"로지스틱 회귀 정확도:\", accuracy_score(y_test, predicted_l))\n",
        "\n",
        "lsvc.fit(tfidfv, y_train)\n",
        "predicted_ls = lsvc.predict(tfidfv_test)\n",
        "print(\"서포트 벡터 머신 정확도:\", accuracy_score(y_test, predicted_ls))\n",
        "\n",
        "tree.fit(tfidfv, y_train)\n",
        "predicted_t = tree.predict(tfidfv_test)\n",
        "print(\"decision tree 정확도:\", accuracy_score(y_test, predicted_t))\n",
        "\n",
        "forest.fit(tfidfv, y_train)\n",
        "predicted_f = forest.predict(tfidfv_test)\n",
        "print(\"random forest 정확도:\", accuracy_score(y_test, predicted_f))\n",
        "\n",
        "grbt.fit(tfidfv, y_train)\n",
        "predicted_gb = grbt.predict(tfidfv_test)\n",
        "print(\"gradient boosting 정확도:\", accuracy_score(y_test, predicted_gb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f6b5f3c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6b5f3c6",
        "outputId": "12145fd6-3f64-46d0-d733-39f85003e78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8165627782724845\n"
          ]
        }
      ],
      "source": [
        "# 소프트 보팅 사용\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "        ('cb', ComplementNB()),\n",
        "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "], voting='soft', n_jobs=-1)\n",
        "voting_classifier.fit(tfidfv, y_train)\n",
        "\n",
        "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fb6a2a1",
      "metadata": {
        "id": "4fb6a2a1"
      },
      "source": [
        "3차 점수 - 단어 15000개\n",
        "* 나이브베이즈 정확도: 0.6331255565449688\n",
        "* 컴플리먼트 나이브 베이즈 정확도: 0.7720391807658059\n",
        "* 로지스틱 회귀 정확도: 0.8125556544968834\n",
        "* 서포트 벡터 머신 정확도: 0.7742653606411398\n",
        "* decision tree 정확도: 0.6193232413178985\n",
        "* random forest 정확도: 0.6714158504007124\n",
        "* gradient boosting 정확도: 0.7707034728406055\n",
        "* 보팅 : 0.8165627782724845"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10073730",
      "metadata": {
        "id": "10073730"
      },
      "source": [
        "# 4. 빈도수 30000개 단어를 사용하기(직접 넣은수치 -  단어 수를 15000개로 지정하였을 때 5000개보다 조금 더 나은 보팅값 향상이 있었기 때문에 추가로 설정)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "bff069b3",
      "metadata": {
        "id": "bff069b3"
      },
      "outputs": [],
      "source": [
        "#num_words는 상위 몇 번째 단어까지 사용할 것인지 \n",
        "#num_words인자를 명시하지 않았을 경우 모든 데이터 사용\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=30000, test_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d7f9c611",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7f9c611",
        "outputId": "316f5334-dfb5-44bd-f6cb-de7d3239dbbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n",
            "2246\n"
          ]
        }
      ],
      "source": [
        "#데이터 복원부분\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "# +3을 한 숫자가 원래 숫자가됨. pad sos unk때문\n",
        "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
        "\n",
        "# index_to_word에 0은 <pad>, 1은 <sos>, 2는 <unk>를 넣기\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token\n",
        "\n",
        "#훈련용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "    \n",
        "x_train = decoded\n",
        "print(len(x_train))\n",
        "\n",
        "#테스트용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b06df623",
      "metadata": {
        "id": "b06df623"
      },
      "outputs": [],
      "source": [
        "#벡터화부분\n",
        "\n",
        "#dtm 생성, dtm이 자체규칙에 따라 불필요하다고 판단하는 토큰을 제거함\n",
        "dtmvector = CountVectorizer()\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "# train에 대한 document - term maxtrix, tfidf 생성\n",
        "x_train_dtm = dtmvector.fit_transform(x_train) #train 데이터를 DTM으로 변환\n",
        "tfidfv = tfidf_transformer.fit_transform(x_train_dtm) #DTM을 TF-IDF 행렬로 변환\n",
        "\n",
        "# test에 대한 document - term maxtrix, tfidf 생성\n",
        "x_test_dtm = dtmvector.transform(x_test) \n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3d4b219c",
      "metadata": {
        "id": "3d4b219c"
      },
      "outputs": [],
      "source": [
        "#모델정의부분\n",
        "\n",
        "nb = MultinomialNB() #나이브베이즈 분류기\n",
        "cb = ComplementNB() #컴플리먼트 나이브 베이즈 분류기 - 나이브베이즈 분류기 개선\n",
        "lr = LogisticRegression(C=10000, penalty='l2') #로지스틱회귀 - 이름은 회귀지만 분류모델\n",
        "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False) # 서포트벡터머신(svm) 사용\n",
        "tree = DecisionTreeClassifier(max_depth=10, random_state=0) #의사결정나무\n",
        "forest = RandomForestClassifier(n_estimators=5, random_state=0) #랜덤포레스트\n",
        "grbt = GradientBoostingClassifier(random_state=0) # 그라디언트부스팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8917b7fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8917b7fe",
        "outputId": "38658e93-6a67-46ad-c890-b9695cb66d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나이브베이즈 정확도: 0.5997328584149599\n",
            "컴플리먼트 나이브 베이즈 정확도: 0.7653606411398041\n",
            "로지스틱 회귀 정확도: 0.8103294746215495\n",
            "서포트 벡터 머신 정확도: 0.7764915405164737\n",
            "decision tree 정확도: 0.622439893143366\n",
            "random forest 정확도: 0.6638468388245771\n",
            "gradient boosting 정확도: 0.7658058771148709\n"
          ]
        }
      ],
      "source": [
        "nb.fit(tfidfv, y_train)\n",
        "predicted_n = nb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"나이브베이즈 정확도:\", accuracy_score(y_test, predicted_n)) #예측값과 실제값 비교\n",
        "\n",
        "cb.fit(tfidfv, y_train)\n",
        "predicted_c = cb.predict(tfidfv_test)\n",
        "print(\"컴플리먼트 나이브 베이즈 정확도:\", accuracy_score(y_test, predicted_c))\n",
        "\n",
        "lr.fit(tfidfv, y_train)\n",
        "predicted_l = lr.predict(tfidfv_test)\n",
        "print(\"로지스틱 회귀 정확도:\", accuracy_score(y_test, predicted_l))\n",
        "\n",
        "lsvc.fit(tfidfv, y_train)\n",
        "predicted_ls = lsvc.predict(tfidfv_test)\n",
        "print(\"서포트 벡터 머신 정확도:\", accuracy_score(y_test, predicted_ls))\n",
        "\n",
        "tree.fit(tfidfv, y_train)\n",
        "predicted_t = tree.predict(tfidfv_test)\n",
        "print(\"decision tree 정확도:\", accuracy_score(y_test, predicted_t))\n",
        "\n",
        "forest.fit(tfidfv, y_train)\n",
        "predicted_f = forest.predict(tfidfv_test)\n",
        "print(\"random forest 정확도:\", accuracy_score(y_test, predicted_f))\n",
        "\n",
        "grbt.fit(tfidfv, y_train)\n",
        "predicted_gb = grbt.predict(tfidfv_test)\n",
        "print(\"gradient boosting 정확도:\", accuracy_score(y_test, predicted_gb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f101f0b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f101f0b8",
        "outputId": "3f93d192-724d-4ca2-88f1-db8243c08c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8130008904719501\n"
          ]
        }
      ],
      "source": [
        "# 소프트 보팅 사용\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "        ('cb', ComplementNB()),\n",
        "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "], voting='soft', n_jobs=-1)\n",
        "voting_classifier.fit(tfidfv, y_train)\n",
        "\n",
        "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62facacb",
      "metadata": {
        "id": "62facacb"
      },
      "source": [
        "4차 점수 - 단어 30000개\n",
        "* 나이브베이즈 정확도: 0.5997328584149599\n",
        "* 컴플리먼트 나이브 베이즈 정확도: 0.7653606411398041\n",
        "* 로지스틱 회귀 정확도: 0.8103294746215495\n",
        "* 서포트 벡터 머신 정확도: 0.7764915405164737\n",
        "* decision tree 정확도: 0.622439893143366\n",
        "* random forest 정확도: 0.6638468388245771\n",
        "* gradient boosting 정확도: 0.7658058771148709\n",
        "* 보팅 : 0.8130008904719501"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d527640a",
      "metadata": {
        "id": "d527640a"
      },
      "source": [
        "# 5. 빈도수 20000개 단어를 사용하기(직접 넣은수치 - 30000개의 단어를 사용하였을 때 보팅 값에서 성능 저하가 있었기 때문에 기존 가장 뛰어난 값을 가진 15000에서 조금만 늘린 20000개를 사용 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "74ed0aea",
      "metadata": {
        "id": "74ed0aea"
      },
      "outputs": [],
      "source": [
        "#num_words는 상위 몇 번째 단어까지 사용할 것인지 \n",
        "#num_words인자를 명시하지 않았을 경우 모든 데이터 사용\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=20000, test_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8867d4ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8867d4ca",
        "outputId": "373ec62f-2fcc-4c6b-89e4-a6e1641f1c7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n",
            "2246\n"
          ]
        }
      ],
      "source": [
        "#데이터 복원부분\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "# +3을 한 숫자가 원래 숫자가됨. pad sos unk때문\n",
        "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
        "\n",
        "# index_to_word에 0은 <pad>, 1은 <sos>, 2는 <unk>를 넣기\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token\n",
        "\n",
        "#훈련용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "    \n",
        "x_train = decoded\n",
        "print(len(x_train))\n",
        "\n",
        "#테스트용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a4721f3c",
      "metadata": {
        "id": "a4721f3c"
      },
      "outputs": [],
      "source": [
        "#벡터화부분\n",
        "\n",
        "#dtm 생성, dtm이 자체규칙에 따라 불필요하다고 판단하는 토큰을 제거함\n",
        "dtmvector = CountVectorizer()\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "# train에 대한 document - term maxtrix, tfidf 생성\n",
        "x_train_dtm = dtmvector.fit_transform(x_train) #train 데이터를 DTM으로 변환\n",
        "tfidfv = tfidf_transformer.fit_transform(x_train_dtm) #DTM을 TF-IDF 행렬로 변환\n",
        "\n",
        "# test에 대한 document - term maxtrix, tfidf 생성\n",
        "x_test_dtm = dtmvector.transform(x_test) \n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6976c974",
      "metadata": {
        "id": "6976c974"
      },
      "outputs": [],
      "source": [
        "#모델정의부분\n",
        "\n",
        "nb = MultinomialNB() #나이브베이즈 분류기\n",
        "cb = ComplementNB() #컴플리먼트 나이브 베이즈 분류기 - 나이브베이즈 분류기 개선\n",
        "lr = LogisticRegression(C=10000, penalty='l2') #로지스틱회귀 - 이름은 회귀지만 분류모델\n",
        "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False) # 서포트벡터머신(svm) 사용\n",
        "tree = DecisionTreeClassifier(max_depth=10, random_state=0) #의사결정나무\n",
        "forest = RandomForestClassifier(n_estimators=5, random_state=0) #랜덤포레스트\n",
        "grbt = GradientBoostingClassifier(random_state=0) # 그라디언트부스팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "582d323b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "582d323b",
        "outputId": "02318260-2cdc-4765-d01f-534a307863f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나이브베이즈 정확도: 0.6193232413178985\n",
            "컴플리먼트 나이브 베이즈 정확도: 0.7671415850400712\n",
            "로지스틱 회귀 정확도: 0.8098842386464826\n",
            "서포트 벡터 머신 정확도: 0.7804986642920748\n",
            "decision tree 정확도: 0.6211041852181657\n",
            "random forest 정확도: 0.6714158504007124\n",
            "gradient boosting 정확도: 0.7702582368655387\n"
          ]
        }
      ],
      "source": [
        "nb.fit(tfidfv, y_train)\n",
        "predicted_n = nb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"나이브베이즈 정확도:\", accuracy_score(y_test, predicted_n)) #예측값과 실제값 비교\n",
        "\n",
        "cb.fit(tfidfv, y_train)\n",
        "predicted_c = cb.predict(tfidfv_test)\n",
        "print(\"컴플리먼트 나이브 베이즈 정확도:\", accuracy_score(y_test, predicted_c))\n",
        "\n",
        "lr.fit(tfidfv, y_train)\n",
        "predicted_l = lr.predict(tfidfv_test)\n",
        "print(\"로지스틱 회귀 정확도:\", accuracy_score(y_test, predicted_l))\n",
        "\n",
        "lsvc.fit(tfidfv, y_train)\n",
        "predicted_ls = lsvc.predict(tfidfv_test)\n",
        "print(\"서포트 벡터 머신 정확도:\", accuracy_score(y_test, predicted_ls))\n",
        "\n",
        "tree.fit(tfidfv, y_train)\n",
        "predicted_t = tree.predict(tfidfv_test)\n",
        "print(\"decision tree 정확도:\", accuracy_score(y_test, predicted_t))\n",
        "\n",
        "forest.fit(tfidfv, y_train)\n",
        "predicted_f = forest.predict(tfidfv_test)\n",
        "print(\"random forest 정확도:\", accuracy_score(y_test, predicted_f))\n",
        "\n",
        "grbt.fit(tfidfv, y_train)\n",
        "predicted_gb = grbt.predict(tfidfv_test)\n",
        "print(\"gradient boosting 정확도:\", accuracy_score(y_test, predicted_gb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "04248f52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04248f52",
        "outputId": "fb4b9337-d2c6-483a-c195-01314423e7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8178984861976848\n"
          ]
        }
      ],
      "source": [
        "# 소프트 보팅 사용\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "        ('cb', ComplementNB()),\n",
        "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "], voting='soft', n_jobs=-1)\n",
        "voting_classifier.fit(tfidfv, y_train)\n",
        "\n",
        "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95da88f8",
      "metadata": {
        "id": "95da88f8"
      },
      "source": [
        "5차 점수 - 단어 20000개\n",
        "* 나이브베이즈 정확도: 0.6193232413178985\n",
        "* 컴플리먼트 나이브 베이즈 정확도: 0.7671415850400712\n",
        "* 로지스틱 회귀 정확도: 0.8098842386464826\n",
        "* 서포트 벡터 머신 정확도: 0.7804986642920748\n",
        "* decision tree 정확도: 0.6211041852181657\n",
        "* random forest 정확도: 0.6714158504007124\n",
        "* gradient boosting 정확도: 0.7702582368655387\n",
        "* 보팅 : 8178984861976848"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eee5b595",
      "metadata": {
        "id": "eee5b595"
      },
      "source": [
        "모든 단어를 사용한 것을 제외하고 단어 수를 20000개로 설정하였을 때 보팅값이 가장 높게 나왔다.\n",
        "너무 많은 단어를 사용하면 좋은 결과를얻지 못하는 경우가 많다고 했는데, 모든 단어를 적용하여도 단어의 수가 적은 편이기 때문에 모든 단어를 사용한 결과값이 가장 많이 나오지 않나로 생각하고 있다.\n",
        "모든 단어를 사용하는 것보다 단어 20000개를 사용한 것을 바탕으로 딥러닝을 진행해보고자 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec308285",
      "metadata": {
        "id": "ec308285"
      },
      "source": [
        "# 6. LSTM을 사용하여 비교(20000개의 단어를 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ae2d10c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae2d10c9",
        "outputId": "a447725e-29e7-41d0-f872-5197862b628c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=20000, test_split=0.2)\n",
        "num_classes = max(y_train) + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 복원부분\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "# +3을 한 숫자가 원래 숫자가됨. pad sos unk때문\n",
        "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
        "\n",
        "# index_to_word에 0은 <pad>, 1은 <sos>, 2는 <unk>를 넣기\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token\n",
        "\n",
        "#훈련용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "    \n",
        "x_train = decoded\n",
        "print(len(x_train))\n",
        "\n",
        "#테스트용 뉴스 데이터 복원\n",
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UitjYHWSskxc",
        "outputId": "e8f2513d-1c81-47a9-b900-e79177f0329a"
      },
      "id": "UitjYHWSskxc",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "565248/550378 [==============================] - 0s 0us/step\n",
            "8982\n",
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(rnn_x_train, rnn_y_train), (rnn_x_test, rnn_y_test) = reuters.load_data(num_words=20000, test_split=0.2)\n",
        "print(len(rnn_x_train), len(rnn_x_test))\n",
        "max_len = max(len(l) for l in np.concatenate((rnn_x_train, rnn_x_test), axis=0))\n",
        "print('max_len : ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxgpMC5wskvI",
        "outputId": "da34914d-a95f-4a37-b2da-a849b462815c"
      },
      "id": "lxgpMC5wskvI",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982 2246\n",
            "max_len :  2376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "rnn_x_train = pad_sequences(rnn_x_train, maxlen=max_len)\n",
        "rnn_x_test = pad_sequences(rnn_x_test, maxlen=max_len)\n",
        "\n",
        "rnn_y_train = to_categorical(rnn_y_train, num_classes=46)\n",
        "rnn_y_test = to_categorical(rnn_y_test, num_classes=46)\n",
        "\n",
        "rnn_x_train = rnn_x_train[1000:]\n",
        "rnn_y_train = rnn_y_train[1000:]\n",
        "rnn_x_val = rnn_x_train[:1000]\n",
        "rnn_y_val = rnn_y_train[:1000]"
      ],
      "metadata": {
        "id": "zeV1l-xCsks4"
      },
      "id": "zeV1l-xCsks4",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "vocab_size = len(index_to_word)\n",
        "print(vocab_size)\n",
        "word_vector_dim = 120\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, word_vector_dim))\n",
        "model.add(keras.layers.LSTM(120))\n",
        "model.add(keras.layers.Dense(46, activation='selu'))\n",
        "# 모델 훈련\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(rnn_x_train, rnn_y_train, epochs=50, callbacks=[es], batch_size=128, validation_data=(rnn_x_val, rnn_y_val), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI4VdnwI19PC",
        "outputId": "f2f5ebc1-3609-4ea1-c7c1-cc4e4ca60d0a"
      },
      "id": "VI4VdnwI19PC",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30982\n",
            "Epoch 1/50\n",
            "63/63 [==============================] - 12s 170ms/step - loss: 0.1003 - accuracy: 0.3816 - val_loss: 0.0880 - val_accuracy: 0.3280\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 11s 168ms/step - loss: 0.0816 - accuracy: 0.3607 - val_loss: 0.0789 - val_accuracy: 0.3720\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 11s 169ms/step - loss: 0.0731 - accuracy: 0.4732 - val_loss: 0.0724 - val_accuracy: 0.5710\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 10s 167ms/step - loss: 0.0696 - accuracy: 0.5915 - val_loss: 0.0667 - val_accuracy: 0.6310\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 10s 165ms/step - loss: 0.0725 - accuracy: 0.6136 - val_loss: 0.1014 - val_accuracy: 0.5680\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 11s 167ms/step - loss: 0.0839 - accuracy: 0.5991 - val_loss: 0.1102 - val_accuracy: 0.5860\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0878 - accuracy: 0.5623 - val_loss: 0.0839 - val_accuracy: 0.5590\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 10s 165ms/step - loss: 0.0664 - accuracy: 0.6293 - val_loss: 0.0640 - val_accuracy: 0.6400\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 10s 166ms/step - loss: 0.0624 - accuracy: 0.6553 - val_loss: 0.0616 - val_accuracy: 0.6580\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 10s 166ms/step - loss: 0.0635 - accuracy: 0.6624 - val_loss: 0.0637 - val_accuracy: 0.6150\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 10s 167ms/step - loss: 0.0589 - accuracy: 0.6719 - val_loss: 0.0596 - val_accuracy: 0.7010\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 11s 167ms/step - loss: 0.0557 - accuracy: 0.7337 - val_loss: 0.0575 - val_accuracy: 0.7530\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 11s 168ms/step - loss: 0.0529 - accuracy: 0.7563 - val_loss: 0.0642 - val_accuracy: 0.6500\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0680 - accuracy: 0.6446 - val_loss: 0.0584 - val_accuracy: 0.6530\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0533 - accuracy: 0.7033 - val_loss: 0.0536 - val_accuracy: 0.7080\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0495 - accuracy: 0.7399 - val_loss: 0.0515 - val_accuracy: 0.7420\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 10s 165ms/step - loss: 0.0475 - accuracy: 0.7715 - val_loss: 0.0506 - val_accuracy: 0.7800\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 10s 165ms/step - loss: 0.0463 - accuracy: 0.7957 - val_loss: 0.0482 - val_accuracy: 0.8080\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 10s 165ms/step - loss: 0.0448 - accuracy: 0.8150 - val_loss: 0.0462 - val_accuracy: 0.8240\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 10s 165ms/step - loss: 0.0430 - accuracy: 0.8271 - val_loss: 0.0449 - val_accuracy: 0.8280\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 10s 165ms/step - loss: 0.0456 - accuracy: 0.8104 - val_loss: 0.0532 - val_accuracy: 0.7490\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 10s 165ms/step - loss: 0.0459 - accuracy: 0.7944 - val_loss: 0.0462 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 10s 165ms/step - loss: 0.0455 - accuracy: 0.8133 - val_loss: 0.0456 - val_accuracy: 0.8150\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0424 - accuracy: 0.8306 - val_loss: 0.0441 - val_accuracy: 0.8340\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0410 - accuracy: 0.8436 - val_loss: 0.0430 - val_accuracy: 0.8390\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0401 - accuracy: 0.8514 - val_loss: 0.0421 - val_accuracy: 0.8480\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0394 - accuracy: 0.8582 - val_loss: 0.0414 - val_accuracy: 0.8520\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0390 - accuracy: 0.8643 - val_loss: 0.0408 - val_accuracy: 0.8590\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0385 - accuracy: 0.8693 - val_loss: 0.0408 - val_accuracy: 0.8630\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0380 - accuracy: 0.8717 - val_loss: 0.0395 - val_accuracy: 0.8680\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0374 - accuracy: 0.8760 - val_loss: 0.0389 - val_accuracy: 0.8690\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 10s 165ms/step - loss: 0.0370 - accuracy: 0.8750 - val_loss: 0.0384 - val_accuracy: 0.8740\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0366 - accuracy: 0.8779 - val_loss: 0.0380 - val_accuracy: 0.8770\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0363 - accuracy: 0.8785 - val_loss: 0.0378 - val_accuracy: 0.8780\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0361 - accuracy: 0.8796 - val_loss: 0.0373 - val_accuracy: 0.8800\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0360 - accuracy: 0.8812 - val_loss: 0.0377 - val_accuracy: 0.8750\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0357 - accuracy: 0.8816 - val_loss: 0.0372 - val_accuracy: 0.8800\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0355 - accuracy: 0.8814 - val_loss: 0.0370 - val_accuracy: 0.8820\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0355 - accuracy: 0.8830 - val_loss: 0.0367 - val_accuracy: 0.8820\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0355 - accuracy: 0.8824 - val_loss: 0.0369 - val_accuracy: 0.8810\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0357 - accuracy: 0.8817 - val_loss: 0.0462 - val_accuracy: 0.8480\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0402 - accuracy: 0.8736 - val_loss: 0.0392 - val_accuracy: 0.8760\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0364 - accuracy: 0.8826 - val_loss: 0.0368 - val_accuracy: 0.8850\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0353 - accuracy: 0.8834 - val_loss: 0.0362 - val_accuracy: 0.8850\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0349 - accuracy: 0.8842 - val_loss: 0.0362 - val_accuracy: 0.8830\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0348 - accuracy: 0.8836 - val_loss: 0.0360 - val_accuracy: 0.8820\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0347 - accuracy: 0.8839 - val_loss: 0.0359 - val_accuracy: 0.8870\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0350 - accuracy: 0.8845 - val_loss: 0.0368 - val_accuracy: 0.8780\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0355 - accuracy: 0.8825 - val_loss: 0.0364 - val_accuracy: 0.8800\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 10s 164ms/step - loss: 0.0353 - accuracy: 0.8846 - val_loss: 0.0374 - val_accuracy: 0.8820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(rnn_x_test, rnn_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6Oi6k8xskjr",
        "outputId": "b67fa48a-e1c1-4cca-9654-e8200e66fd35"
      },
      "id": "I6Oi6k8xskjr",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 34ms/step - loss: 0.1356 - accuracy: 0.6309\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13564540445804596, 0.6308993697166443]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고"
      ],
      "metadata": {
        "id": "vhpiGg4jBAIC"
      },
      "id": "vhpiGg4jBAIC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신러닝에 비해서 딥러닝이 제대로된 학습을 하지 못하였다. 모든 단어를 사용했던 기법을 제외한 보팅 기법에서 가장 높은 성능을 보였던 20000개의 단어를 바탕으로 딥러닝을 시도 하였는데, 20000개라는 단어가 문제인 듯 싶다.비슷한 모델에 10000개의 단어를 사용한 분의 결과는 괜찮았기 때문이다. 단순히 보팅에서 가장 높은 성과를 얻은 상위 단어의 수를 사용하는 것보다 f1스코어 등등 여러가지를 고려하는 것이 필요해 보인다."
      ],
      "metadata": {
        "id": "fejk2IJrA2WO"
      },
      "id": "fejk2IJrA2WO"
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IwtYXWilA1Ks"
      },
      "id": "IwtYXWilA1Ks"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "[Going_Deeper-4] news_data_confirm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}